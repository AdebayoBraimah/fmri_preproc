{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from typing import (\n",
    "    List,\n",
    "    Tuple,\n",
    "    Optional,\n",
    "    Union\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "def generate_bvals(num_frames: int,\n",
    "                   out_file: str = 'file.bval'\n",
    "                  ) -> str:\n",
    "    \"\"\"Creates/generates an arbitrary number b=0 b-values for a fMRI acquisition\n",
    "    provided the number of dynamics/temporal frames.\n",
    "    \n",
    "    Usage example:\n",
    "        >>> bval_file = generate_bvals(num_frames=1200, out_file=\"fmri.bval\")\n",
    "        \n",
    "    Arguments:\n",
    "        num_frames: Number of temporal frames/dynamics.\n",
    "        out_file: Output file name.\n",
    "        \n",
    "    Returns:\n",
    "        Output file path as string that contains the corresponding b-values.\n",
    "    \n",
    "    Raises:\n",
    "        TypeError: Exception that is raised when the input for ``num_frames`` is not an ``int``.\n",
    "    \"\"\"\n",
    "    if type(num_frames) != int:\n",
    "        raise TypeError(f\"Input for num_frames: {num_frames} is not an integer.\")\n",
    "        \n",
    "    np.savetxt(out_file,\n",
    "               np.zeros((1,num_frames),\n",
    "                        dtype=np.int8,\n",
    "                        order='C'),\n",
    "               fmt='%i',\n",
    "               delimiter=' ',\n",
    "               encoding='utf-8')\n",
    "    out_file: str = os.path.abspath(out_file)\n",
    "    return out_file"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "def generate_bvecs(num_frames: int,\n",
    "                   out_file: str = 'file.bvec'\n",
    "                  ) -> str:\n",
    "    \"\"\"Creates/generates an arbitrary number of x,y,z b-vectors for a fMRI acquisition\n",
    "    provided the number of dynamics/temporal frames.\n",
    "    \n",
    "    Usage example:\n",
    "        >>> bval_file = generate_bvecs(num_frames=1200, out_file=\"fmri.bvec\")\n",
    "        \n",
    "    Arguments:\n",
    "        num_frames: Number of temporal frames/dynamics.\n",
    "        out_file: Output file name.\n",
    "        \n",
    "    Returns:\n",
    "        Output file path as string that contains the corresponding b-vectors.\n",
    "    \n",
    "    Raises:\n",
    "        TypeError: Exception that is raised when the input for ``num_frames`` is not an ``int``.\n",
    "    \"\"\"\n",
    "    if type(num_frames) != int:\n",
    "        raise TypeError(f\"Input for num_frames: {num_frames} is not an integer.\")\n",
    "        \n",
    "    np.savetxt(out_file,\n",
    "               np.ones((1,num_frames),dtype=np.int8,order='C') * np.array([[1], [0], [0]]),\n",
    "               fmt='%i',\n",
    "               delimiter=' ',\n",
    "               encoding='utf-8')\n",
    "    out_file: str = os.path.abspath(out_file)\n",
    "    return out_file"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "def generate_acq_params(num_frames: int,\n",
    "                        effective_echo_spacing: float = 0.05,\n",
    "                        out_prefix: str = 'file'\n",
    "                       ) -> Tuple[str,str]:\n",
    "    \"\"\"Creates acquisition parameters files for fMRI acquisition provided the number of frames and the \n",
    "    effective echo spacing.\n",
    "    \n",
    "    Usage example:\n",
    "        >>> dist_acqp, func_acqp = generate_acq_params(num_frames=1200, \n",
    "        ...                                            effective_echo_spacing=0.05,\n",
    "        ...                                            out_prefix=\"fmri\")\n",
    "        ...\n",
    "        \n",
    "    Arguments:\n",
    "        num_frames: Number of temporal frames/dynamics.\n",
    "        effective_echo_spacing: Effective echo spacing.\n",
    "        out_prefix: Output file prefix.\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of strings that correspond to the acquisition parameter files (for both distortion correction and\n",
    "            eddy current correction).\n",
    "    \n",
    "    Raises:\n",
    "        TypeError: Exception that is raised when either ``num_frames`` is not an ``int`` OR when ``effective_echo_spacing`` is not a ``float``.\n",
    "    \"\"\"\n",
    "    if (type(num_frames) != int) or (type(effective_echo_spacing) != float):\n",
    "        raise TypeError(f\"Input for num_frames: {num_frames} is not an integer OR effective_echo_spacing: {effective_echo_spacing} is not a float.\")\n",
    "    \n",
    "    # Generate distortion correction\n",
    "    out_dist: str = out_prefix + \"_distortion_correction.acqp\"\n",
    "    out_func: str = out_prefix + \"_functional.acqp\"\n",
    "    \n",
    "    # Write distortion correction acqp file\n",
    "    with open(out_dist,'w') as f:\n",
    "        f.write(f\"0 1 0 {effective_echo_spacing}\\n\")\n",
    "        f.write(f\"0 -1 0 {effective_echo_spacing}\\n\")\n",
    "        f.close()\n",
    "    \n",
    "    # Write functinoal acqp file\n",
    "    with open(out_func,'w') as f:\n",
    "        for i in range(0,num_frames):\n",
    "            f.write(f\"0 1 0 {effective_echo_spacing}\\n\")\n",
    "        f.close()\n",
    "    \n",
    "    # Obtain absolute file paths\n",
    "    out_dist: str = os.path.abspath(out_dist)\n",
    "    out_func: str = os.path.abspath(out_func)\n",
    "    \n",
    "    return out_dist, out_func"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "def generate_index(num_frames: int,\n",
    "                   out_file: str = 'file.idx'\n",
    "                  ) -> str:\n",
    "    \"\"\"Creates index files for use with FSL's ``eddy``.\n",
    "    \n",
    "    Usage example:\n",
    "        >>> func_idx = generate_index(num_frames=1200, out_file=\"fmri.idx\")\n",
    "        \n",
    "    Arguments:\n",
    "        num_frames: Number of temporal frames/dynamics.\n",
    "        out_file: Output file name.\n",
    "        \n",
    "    Returns:\n",
    "        Output file path as string that contains the corresponding frame indices.\n",
    "    \n",
    "    Raises:\n",
    "        TypeError: Exception that is raised when the input for ``num_frames`` is not an ``int``.\n",
    "    \"\"\"\n",
    "    if type(num_frames) != int:\n",
    "        raise TypeError(f\"Input for num_frames: {num_frames} is not an integer.\")\n",
    "    return np.savetxt(out_file, np.ones((1, num_frames)).T, fmt=\"%i\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "generate_bvals(400)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'file.bval'"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "generate_bvecs(400)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'file.bvec'"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "generate_index(400)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "generate_acq_params(0.05,400)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "('file_distortion_correction.acqp', 'file_functional.acqp')"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "source": [
    "# slices = 45\n",
    "slices = 15"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "source": [
    "# mb_factor = 9\n",
    "mb_factor = 3"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "source": [
    "locs = slices//mb_factor\n",
    "locs"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "metadata": {},
     "execution_count": 217
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "source": [
    "step = int(np.round(np.sqrt(locs)))\n",
    "step\n",
    "# step = 1"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "metadata": {},
     "execution_count": 218
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "source": [
    "# This works for interleaved data\n",
    "n = []\n",
    "for s in range(step):\n",
    "    for k in range(s, locs, step):\n",
    "        if mb_factor != 1:\n",
    "            a = [k + locs*j for j in range(mb_factor)]\n",
    "            n.append(a)\n",
    "        else:\n",
    "            a = k\n",
    "            n.append(a)\n",
    "n = np.array(n)\n",
    "# n = np.transpose(n)\n",
    "n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[ 0,  5, 10],\n",
       "       [ 2,  7, 12],\n",
       "       [ 4,  9, 14],\n",
       "       [ 1,  6, 11],\n",
       "       [ 3,  8, 13]])"
      ]
     },
     "metadata": {},
     "execution_count": 219
    }
   ],
   "metadata": {
    "scrolled": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "source": [
    "slices = 45\n",
    "mb_factor = 9"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "source": [
    "locs = slices//mb_factor\n",
    "locs"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "metadata": {},
     "execution_count": 133
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "source": [
    "# step = int(np.round(np.sqrt(locs)))\n",
    "# step\n",
    "step = 1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "source": [
    "# This single shot data\n",
    "n = []\n",
    "for s in range(step):\n",
    "    # print(s)\n",
    "    for k in range(locs):\n",
    "        # print(k)\n",
    "        if mb_factor != 1:\n",
    "            a = [k + locs*n for n in range(mb_factor)]\n",
    "            n.append(a)\n",
    "        else:\n",
    "            a = k\n",
    "            n.append(a)\n",
    "    n = np.array(n)\n",
    "# n = np.transpose(n)\n",
    "n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[ 0,  5, 10, 15, 20, 25, 30, 35, 40],\n",
       "       [ 1,  6, 11, 16, 21, 26, 31, 36, 41],\n",
       "       [ 2,  7, 12, 17, 22, 27, 32, 37, 42],\n",
       "       [ 3,  8, 13, 18, 23, 28, 33, 38, 43],\n",
       "       [ 4,  9, 14, 19, 24, 29, 34, 39, 44]])"
      ]
     },
     "metadata": {},
     "execution_count": 140
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "def generate_slice_order(slices: int,\n",
    "                         mb_factor: int = 1,\n",
    "                         mode: str = 'interleaved',\n",
    "                         out_file: str = 'file.slice.order',\n",
    "                         return_mat: Optional[bool] = False\n",
    "                        ) -> Union[str,np.array]:\n",
    "    \"\"\"Generates the slice acquisition order file for use with ``eddy's`` slice-to-volume motion correction method.\n",
    "    \n",
    "    The file generated consists of an (N/m) x m matrix | N = number of slices in the acquisition direction (assumed to be\n",
    "    the z-direction), and m = multi-band factor.\n",
    "    \n",
    "    NOTE:\n",
    "        Links for details:\n",
    "            * Documentation: https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/eddy/UsersGuide#A--slspec\n",
    "            * Implementation: https://git.fmrib.ox.ac.uk/seanf/dhcp-neonatal-fmri-pipeline/-/blob/master/dhcp/resources/default_func.slorder\n",
    "            * Implementation: https://git.fmrib.ox.ac.uk/matteob/dHCP_neo_dMRI_pipeline_release/-/blob/master/slorder.txt\n",
    "    \n",
    "    Usage example:\n",
    "        >>> sls_order = generate_slice_order(slices=44,\n",
    "        ...                                  mb_factor=6,\n",
    "        ...                                  mode='single-shot',\n",
    "        ...                                  out_file='file.slice.order',\n",
    "        ...                                  return_mat=False)\n",
    "        ...\n",
    "        \n",
    "    Arguments:\n",
    "        slices: Number of slices in the acquisition direction.\n",
    "        mb_factor: Multi-band factor.\n",
    "        mode: Acquisition algorithm/method/scheme used to acquire the data. Valid options include:\n",
    "            * ``interleaved``: Optimal slice acquisition technique in which non-adjacent slices are acquired (best for diffusion MR images).\n",
    "            * ``single-shot``: Slice acquisition in which slices are acquired sequentially with an ascending slice order (best for functional MR images).\n",
    "            * ``default``: Default acquisition order in which slices are acquired with an ascending slice order.\n",
    "        out_file: Output file name.\n",
    "        return_mat: Return a numpy multi-dimensional array (matrix) rather than a file.\n",
    "        \n",
    "    Returns:\n",
    "        Output file path as string that contains the slice acquisition order OR a numpy multi-dimensional array if specified.\n",
    "    \n",
    "    Raises:\n",
    "        TypeError: Exception that is raised in the case that either ``slices`` or ``mb_factor`` is not an ``int``.\n",
    "        ValueError: Exception that is raised in the case that neither ``interleaved``, ``single-shot``, or ``default`` is passed as an argument for ``mode``.\n",
    "    \"\"\"\n",
    "    # Check input types\n",
    "    if (type(slices) != int) or (type(mb_factor) != int):\n",
    "        raise TypeError(f\"Input option slices: {slices} or mb_factor: {mb_factor} is not an integer.\")\n",
    "    \n",
    "    # Locations (in the slices) divided by Multi-Band Factor\n",
    "    locs: int = slices//mb_factor\n",
    "    \n",
    "    if mode == 'interleaved':\n",
    "        step: int = int(np.round(np.sqrt(locs)))\n",
    "    elif mode == 'default':\n",
    "        step: int = 2\n",
    "    elif mode == 'single-shot':\n",
    "        step: int = 1\n",
    "    else:\n",
    "        raise ValueError(f\"Option specified for mode: {mode} does not exist.\")\n",
    "    \n",
    "    # Iterate through each MB acquisition to get slice ordering\n",
    "    n: List[int] = []\n",
    "    \n",
    "    for s in range(step):\n",
    "        for k in range(s, locs, step):\n",
    "            if mb_factor != 1:\n",
    "                a: List[int] = [ k + locs*j for j in range(mb_factor) ]\n",
    "                n.append(a)\n",
    "            else:\n",
    "                a: int = k\n",
    "                n.append(a)\n",
    "    \n",
    "    if return_mat:\n",
    "        return np.array(n)\n",
    "    \n",
    "    slice_order: np.arrary = np.array(n)\n",
    "    np.savetxt(out_file,\n",
    "               slice_order, \n",
    "               fmt=\"%i\")\n",
    "    return out_file"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "k = 5"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "type(k).as_integer_ratio()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(100, 1)"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "n = np.array([[0,1,2,3,4]]).T\n",
    "# n = np.transpose(n).T\n",
    "n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [2],\n",
       "       [3],\n",
       "       [4]])"
      ]
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "n.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(5, 1)"
      ]
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "mb_factor = 4"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "slices = 44"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "source": [
    "a = []\n",
    "for i in range(0,mb_factor):\n",
    "    # print(i)\n",
    "    n = []\n",
    "    for j in range(i,slices,mb_factor):\n",
    "        n.append(j)\n",
    "    n = np.array([n])\n",
    "    a.append(n)\n",
    "# a = tuple(a)\n",
    "# a = np.concatenate(a)\n",
    "a"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[array([[ 0,  4,  8, 12, 16, 20, 24, 28, 32, 36, 40]]),\n",
       " array([[ 1,  5,  9, 13, 17, 21, 25, 29, 33, 37, 41]]),\n",
       " array([[ 2,  6, 10, 14, 18, 22, 26, 30, 34, 38, 42]]),\n",
       " array([[ 3,  7, 11, 15, 19, 23, 27, 31, 35, 39, 43]])]"
      ]
     },
     "metadata": {},
     "execution_count": 47
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# for i in range(0,)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "source": [
    "# Looks cool - but was the incorrect method - this always assumed that the MB factor was 9.\n",
    "# \n",
    "# \n",
    "# def generate_slice_order(slices: int,\n",
    "#                          mb_factor: int = 1,\n",
    "#                          out_file: str = 'file.slice.order',\n",
    "#                          return_mat: Optional[bool] = False\n",
    "#                         ) -> Union[str,np.array]:\n",
    "#     \"\"\"working doc-string\n",
    "    \n",
    "#     link for details: https://git.fmrib.ox.ac.uk/seanf/dhcp-neonatal-fmri-pipeline/-/blob/master/dhcp/resources/default_func.slorder\n",
    "#     \"\"\"\n",
    "#     try:\n",
    "#         slice_order: List[int] = []\n",
    "#         for i in range(0,mb_factor):\n",
    "#             n: List[int] = []\n",
    "#             for j in range(i,slices+1,mb_factor):\n",
    "#                 n.append(j)\n",
    "#             n: np.array = np.array([n])\n",
    "#             slice_order.append(n)\n",
    "        \n",
    "#         if return_mat:\n",
    "#             return np.concatenate(slice_order)\n",
    "        \n",
    "#         slice_order: np.arrary = np.concatenate(slice_order)\n",
    "#         np.savetxt(out_file,\n",
    "#                    slice_order, \n",
    "#                    fmt=\"%i\")\n",
    "#         return out_file\n",
    "#     except ValueError:\n",
    "#         return generate_slice_order(slices=slices-1,\n",
    "#                                     mb_factor=mb_factor,\n",
    "#                                     return_mat=return_mat)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "slice_order_mat: np.array = generate_slice_order(slices=45,mb_factor=9,mode='single-shot',return_mat=True)\n",
    "slice_order_mat"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[ 0,  5, 10, 15, 20, 25, 30, 35, 40],\n",
       "       [ 1,  6, 11, 16, 21, 26, 31, 36, 41],\n",
       "       [ 2,  7, 12, 17, 22, 27, 32, 37, 42],\n",
       "       [ 3,  8, 13, 18, 23, 28, 33, 38, 43],\n",
       "       [ 4,  9, 14, 19, 24, 29, 34, 39, 44]])"
      ]
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "# Define the mp_order (Movement parameter order)\n",
    "mp_order: int = slice_order_mat.shape[0]-1\n",
    "mp_order"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import numpy as np\n",
    "import nibabel as nib"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "nii_file = \"b0s.nii.gz\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "img = nib.load(nii_file)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "img.header['dim'][3]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "2%2"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "def _is_even(num: int) -> bool:\n",
    "    \"\"\"working doc-string\n",
    "    \"\"\"\n",
    "    if (num%2 == 0):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "_is_even(44)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Test ``utils`` implementation details"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import os\n",
    "import nibabel as nib"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import util"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "t = util.File(file=\"\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "t"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": []
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "nii_file = 'test.func.nii.gz'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "# with util.NiiFile(nii_file) as f:\n",
    "#     # print(f.abs_path())\n",
    "#     print(f.file_parts())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "f = util.NiiFile(nii_file)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# f.write_txt(txt=\"some text\",header_field=util.NiiHeaderField.intent_name)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# f.touch()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "import sys"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# New implementation\n",
    "sys.getsizeof(f)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# Old implementation\n",
    "sys.getsizeof(f)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "f = util.NiiFile(nii_file)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "f_header = nib.load(f.file)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "print(f_header)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'nibabel.nifti1.Nifti1Image'>\n",
      "data shape (64, 64, 44, 400)\n",
      "affine: \n",
      "[[ -2.5          0.           0.          73.41090393]\n",
      " [  0.           2.5          0.         -35.51405334]\n",
      " [  0.           0.           2.5        -34.53044128]\n",
      " [  0.           0.           0.           1.        ]]\n",
      "metadata:\n",
      "<class 'nibabel.nifti1.Nifti1Header'> object, endian='<'\n",
      "sizeof_hdr      : 348\n",
      "data_type       : b''\n",
      "db_name         : b''\n",
      "extents         : 16384\n",
      "session_error   : 0\n",
      "regular         : b'r'\n",
      "dim_info        : 0\n",
      "dim             : [  4  64  64  44 400   1   1   1]\n",
      "intent_p1       : 0.0\n",
      "intent_p2       : 0.0\n",
      "intent_p3       : 0.0\n",
      "intent_code     : none\n",
      "datatype        : float32\n",
      "bitpix          : 32\n",
      "slice_start     : 0\n",
      "pixdim          : [-1.         2.5        2.5        2.5        1.1997647  0.\n",
      "  0.         0.       ]\n",
      "vox_offset      : 0.0\n",
      "scl_slope       : nan\n",
      "scl_inter       : nan\n",
      "slice_end       : 0\n",
      "slice_code      : unknown\n",
      "xyzt_units      : 10\n",
      "cal_max         : 0.0\n",
      "cal_min         : 0.0\n",
      "slice_duration  : 0.0\n",
      "toffset         : 0.0\n",
      "glmax           : 0\n",
      "glmin           : 0\n",
      "descrip         : b'6.0.3:b862cdd5'\n",
      "aux_file        : b'imgComments'\n",
      "qform_code      : scanner\n",
      "sform_code      : scanner\n",
      "quatern_b       : 0.0\n",
      "quatern_c       : 1.0\n",
      "quatern_d       : 0.0\n",
      "qoffset_x       : 73.410904\n",
      "qoffset_y       : -35.514053\n",
      "qoffset_z       : -34.53044\n",
      "srow_x          : [-2.5       0.        0.       73.410904]\n",
      "srow_y          : [  0.         2.5        0.       -35.514053]\n",
      "srow_z          : [  0.        0.        2.5     -34.53044]\n",
      "intent_name     : b'Test string'\n",
      "magic           : b'n+1'\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "f_header.header['intent_name'] = \"Test string is this greater than 16-bytes?\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "nib.save(f_header,f.file)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "len(\"Test string is t\")"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "f.ext"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'.nii.gz'"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "work = util.WorkDir(work_dir=\"test.workdir\",use_cwd=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "work.mkdir()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "work.rmdir()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "tmp = util.TmpDir(tmp_dir=os.getcwd(),use_cwd=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "tmp"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "/Users/adebayobraimah/Desktop/projects/fmri_preproc/tmp_dir_1153"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "tmp.parent_dir"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'/Users/adebayobraimah/Desktop/projects/fmri_preproc'"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "tmp.mkdir()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "tmp_file = util.TmpDir.TmpFile(tmp_dir=tmp.tmp_dir,ext='nii.gz')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "tmp_file"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "/Users/adebayobraimah/Desktop/projects/fmri_preproc/tmp_dir_8434/tmp_file_1682.nii.gz"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "tmp_file.touch()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "tmp.rmdir()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Define `Enums`"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "from enum import(\n",
    "    Enum,\n",
    "    unique\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "@unique\n",
    "class NiiHeaderField(Enum):\n",
    "    descrip: int = 1\n",
    "    intent_name: int = 2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "NiiHeaderField.descrip == NiiHeaderField.descrip"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "NiiHeaderField.ssss"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "ssss",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-11b30c450c86>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mNiiHeaderField\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mssss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.8/enum.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(cls, name)\u001b[0m\n\u001b[1;32m    382\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_member_map_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: ssss"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "import sys"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "ff = util.File(file=\"test.file.txt\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# New implementation\n",
    "sys.getsizeof(ff)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "# Old implementation\n",
    "sys.getsizeof(ff)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from fslpy import eddy\n",
    "from util import Command"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "eddy(\"\",\"\",\"\",\"\",\"\",\"\",\"\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "command: eddy_cuda7.5 \n",
      " Failed with returncode -6\n",
      "ERROR: dyld: Library not loaded: @rpath/libcublas.7.5.dylib\n",
      "  Referenced from: /usr/local/fsl/6.0.5/bin/eddy_cuda7.5\n",
      "  Reason: image not found\n",
      "\n",
      "command: eddy \n",
      " Failed with returncode 1\n",
      "ERROR: ***************************************************\n",
      "The following COMPULSORY options have not been set:\n",
      "\t--imain\tFile containing all the images to estimate distortions for\n",
      "\t--mask\tMask to indicate brain\n",
      "\t--index\tFile containing indices for all volumes in --imain into --acqp and --topup\n",
      "\t--acqp\tFile containing acquisition parameters\n",
      "\t--bvecs\tFile containing the b-vectors for all volumes in --imain\n",
      "\t--bvals\tFile containing the b-values for all volumes in --imain\n",
      "\t--out\tBasename for output\n",
      "***************************************************\n",
      "\n",
      "Part of FSL (ID: 6.0.5:9e026117)\n",
      "eddy \n",
      "Copyright(c) 2015, University of Oxford (Jesper Andersson)\n",
      "\n",
      "Usage: \n",
      "eddy --monsoon\n",
      "\n",
      "Compulsory arguments (You MUST set one or more of):\n",
      "\t--imain\tFile containing all the images to estimate distortions for\n",
      "\t--mask\tMask to indicate brain\n",
      "\t--index\tFile containing indices for all volumes in --imain into --acqp and --topup\n",
      "\t--acqp\tFile containing acquisition parameters\n",
      "\t--bvecs\tFile containing the b-vectors for all volumes in --imain\n",
      "\t--bvals\tFile containing the b-values for all volumes in --imain\n",
      "\t--out\tBasename for output\n",
      "\n",
      "Optional arguments (You may optionally specify one or more of):\n",
      "\t--mb\tMulti-band factor\n",
      "\t--mb_offs\tMulti-band offset (-1 if bottom slice removed, 1 if top slice removed)\n",
      "\t--slspec\tName of text file completely specifying slice/group acuistion. N.B. --slspec and --json are mutually exclusive.\n",
      "\t--json\tName of .json text file with information about slice timing. N.B. --json and --slspec are mutually exclusive.\n",
      "\t--mporder\tOrder of slice-to-vol movement model (default 0, i.e. vol-to-vol\n",
      "\t--s2v_lambda\tRegularisation weight for slice-to-vol movement. (default 1, reasonable range 1--10\n",
      "\t--topup\tBase name for output files from topup\n",
      "\t--field\tName of file with susceptibility field (in Hz)\n",
      "\t--field_mat\tName of rigid body transform for susceptibility field\n",
      "\t--flm\tFirst level EC model (movement/linear/quadratic/cubic, default quadratic)\n",
      "\t--slm\tSecond level EC model (none/linear/quadratic, default none)\n",
      "\t--fwhm\tFWHM for conditioning filter when estimating the parameters (default 0)\n",
      "\t--niter\tNumber of iterations (default 5)\n",
      "\t--s2v_niter\tNumber of iterations for slice-to-vol (default 5)\n",
      "\t--cnr_maps\tWrite shell-wise cnr-maps (default false)\n",
      "\t--residuals\tWrite residuals (between GP and observations), (default false)\n",
      "\t--fep\tFill empty planes in x- or y-directions (default false)\n",
      "\t--interp\tInterpolation model for estimation step (spline/trilinear, default spline)\n",
      "\t--s2v_interp\tSlice-to-vol interpolation model for estimation step (spline/trilinear, default trilinear)\n",
      "\t--resamp\tFinal resampling method (jac/lsr, default jac)\n",
      "\t--nvoxhp\t# of voxels used to estimate the hyperparameters (default 1000)\n",
      "\t--initrand\tSeeds rand for when selecting voxels (default 0=no seeding)\n",
      "\t--ff\tFudge factor for hyperparameter error variance (default 10.0)\n",
      "\t--repol\tDetect and replace outlier slices (default false))\n",
      "\t--ol_nstd\tNumber of std off to qualify as outlier (default 4)\n",
      "\t--ol_nvox\tMin # of voxels in a slice for inclusion in outlier detection (default 250)\n",
      "\t--ol_type\tType of outliers, slicewise (sw), groupwise (gw) or both (both). (default sw)\n",
      "\t--ol_pos\tConsider both positive and negative outliers if set (default false)\n",
      "\t--ol_sqr\tConsider outliers among sums-of-squared differences if set (default false)\n",
      "\t--estimate_move_by_susceptibility\tEstimate how susceptibility field changes with subject movement (default false)\n",
      "\t--mbs_niter\tNumber of iterations for MBS estimation (default 10)\n",
      "\t--mbs_lambda\tWeighting of regularisation for MBS estimation (default 10)\n",
      "\t--mbs_ksp\tKnot-spacing for MBS field estimation (default 10mm)\n",
      "\t--dont_sep_offs_move\tDo NOT attempt to separate field offset from subject movement (default false)\n",
      "\t--dont_peas\tDo NOT perform a post-eddy alignment of shells (default false)\n",
      "\t--data_is_shelled\tAssume, don't check, that data is shelled (default false)\n",
      "\t-v,--verbose\tswitch on diagnostic messages\n",
      "\t-h,--help\tdisplay this message\n",
      "\n",
      "\n",
      "\n",
      "eddy\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "p = Command(\"eddy\")\n",
    "# p.cmd_list.append(\"-h\")\n",
    "p.run()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "command: eddy \n",
      " Failed with returncode 1\n",
      "ERROR: ***************************************************\n",
      "The following COMPULSORY options have not been set:\n",
      "\t--imain\tFile containing all the images to estimate distortions for\n",
      "\t--mask\tMask to indicate brain\n",
      "\t--index\tFile containing indices for all volumes in --imain into --acqp and --topup\n",
      "\t--acqp\tFile containing acquisition parameters\n",
      "\t--bvecs\tFile containing the b-vectors for all volumes in --imain\n",
      "\t--bvals\tFile containing the b-values for all volumes in --imain\n",
      "\t--out\tBasename for output\n",
      "***************************************************\n",
      "\n",
      "Part of FSL (ID: 6.0.5:9e026117)\n",
      "eddy \n",
      "Copyright(c) 2015, University of Oxford (Jesper Andersson)\n",
      "\n",
      "Usage: \n",
      "eddy --monsoon\n",
      "\n",
      "Compulsory arguments (You MUST set one or more of):\n",
      "\t--imain\tFile containing all the images to estimate distortions for\n",
      "\t--mask\tMask to indicate brain\n",
      "\t--index\tFile containing indices for all volumes in --imain into --acqp and --topup\n",
      "\t--acqp\tFile containing acquisition parameters\n",
      "\t--bvecs\tFile containing the b-vectors for all volumes in --imain\n",
      "\t--bvals\tFile containing the b-values for all volumes in --imain\n",
      "\t--out\tBasename for output\n",
      "\n",
      "Optional arguments (You may optionally specify one or more of):\n",
      "\t--mb\tMulti-band factor\n",
      "\t--mb_offs\tMulti-band offset (-1 if bottom slice removed, 1 if top slice removed)\n",
      "\t--slspec\tName of text file completely specifying slice/group acuistion. N.B. --slspec and --json are mutually exclusive.\n",
      "\t--json\tName of .json text file with information about slice timing. N.B. --json and --slspec are mutually exclusive.\n",
      "\t--mporder\tOrder of slice-to-vol movement model (default 0, i.e. vol-to-vol\n",
      "\t--s2v_lambda\tRegularisation weight for slice-to-vol movement. (default 1, reasonable range 1--10\n",
      "\t--topup\tBase name for output files from topup\n",
      "\t--field\tName of file with susceptibility field (in Hz)\n",
      "\t--field_mat\tName of rigid body transform for susceptibility field\n",
      "\t--flm\tFirst level EC model (movement/linear/quadratic/cubic, default quadratic)\n",
      "\t--slm\tSecond level EC model (none/linear/quadratic, default none)\n",
      "\t--fwhm\tFWHM for conditioning filter when estimating the parameters (default 0)\n",
      "\t--niter\tNumber of iterations (default 5)\n",
      "\t--s2v_niter\tNumber of iterations for slice-to-vol (default 5)\n",
      "\t--cnr_maps\tWrite shell-wise cnr-maps (default false)\n",
      "\t--residuals\tWrite residuals (between GP and observations), (default false)\n",
      "\t--fep\tFill empty planes in x- or y-directions (default false)\n",
      "\t--interp\tInterpolation model for estimation step (spline/trilinear, default spline)\n",
      "\t--s2v_interp\tSlice-to-vol interpolation model for estimation step (spline/trilinear, default trilinear)\n",
      "\t--resamp\tFinal resampling method (jac/lsr, default jac)\n",
      "\t--nvoxhp\t# of voxels used to estimate the hyperparameters (default 1000)\n",
      "\t--initrand\tSeeds rand for when selecting voxels (default 0=no seeding)\n",
      "\t--ff\tFudge factor for hyperparameter error variance (default 10.0)\n",
      "\t--repol\tDetect and replace outlier slices (default false))\n",
      "\t--ol_nstd\tNumber of std off to qualify as outlier (default 4)\n",
      "\t--ol_nvox\tMin # of voxels in a slice for inclusion in outlier detection (default 250)\n",
      "\t--ol_type\tType of outliers, slicewise (sw), groupwise (gw) or both (both). (default sw)\n",
      "\t--ol_pos\tConsider both positive and negative outliers if set (default false)\n",
      "\t--ol_sqr\tConsider outliers among sums-of-squared differences if set (default false)\n",
      "\t--estimate_move_by_susceptibility\tEstimate how susceptibility field changes with subject movement (default false)\n",
      "\t--mbs_niter\tNumber of iterations for MBS estimation (default 10)\n",
      "\t--mbs_lambda\tWeighting of regularisation for MBS estimation (default 10)\n",
      "\t--mbs_ksp\tKnot-spacing for MBS field estimation (default 10mm)\n",
      "\t--dont_sep_offs_move\tDo NOT attempt to separate field offset from subject movement (default false)\n",
      "\t--dont_peas\tDo NOT perform a post-eddy alignment of shells (default false)\n",
      "\t--data_is_shelled\tAssume, don't check, that data is shelled (default false)\n",
      "\t-v,--verbose\tswitch on diagnostic messages\n",
      "\t-h,--help\tdisplay this message\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1, None, None)"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a0afd39b322e8f65b39096d63bb597abf283a7f58195bb577f9b5a76e499c911"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}